---
title: "Bringing Portal Data to Other Platforms (cBioPortal)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bringing Portal Data to Other Platforms (cBioPortal)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**Document Status:** Draft  
**Estimated Reading Time:** 5 min

## Special acknowledgments 

Functionality demonstrated in this vignette benefited greatly from code originally written by [hhunterzinck](https://github.com/hhunterzinck). 

## Intro

This briefly describes usage for bringing data from NF-OSI (mainly NF-OSI processed data) is brought to other platforms (mainly cBioPortal). 

## Set up

First load the `nfportalutils` package and log in. 
The recommended default usage of `syn_login` is to use it without directly passing in credentials. 
Instead, have available the `SYNAPSE_AUTH_TOKEN` environment variable with your token stored therein. 
```{r setup}
library(nfportalutils)
syn_login()
```

## Creating a mutations dataset

Compilation of a cBioPortal dataset does require putting together a number of assets on Synapse and elsewhere, but the package should make it seem as straightforward as possible.

- `merged_maf` references a final output file from the NF-OSI processing pipeline that is directly ready for public release. No modifications are needed for this file (except renaming it).
- `ref_view` is a fileview that contains annotations for the files released.
- `samplesheet` is a the samplesheet used for the data processing and ultimately creating `merged_maf`
- `ref_map` maps clinical variables from the NF-OSI data dictionary to cBioPortal's

```{r files}
merged_maf <- "syn36553188"
ref_view <- "syn43278088"
samplesheet <- "syn41830510"
ref_map <- "https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/b615da50f20a47dabbd98ac69329f374f82bc5ea/mappings/cBioPortal.yaml"
```


This will create a folder with the set of files needed.
```{r syncBP_maf}

syncBP_maf(merged_maf,
           samplesheet,
           ref_map,
           ref_view)
```

## Updating or adding to a dataset

This is a TO-DO section.

## Validation

There are additional steps such as validation that have to be done outside of the package with either your custom cBioPortal backend or [this validator](https://github.com/cBioPortal/datahub-study-curation-tools/tree/master/validation/validator).
See also [docs for the dataset validation](https://docs.cbioportal.org/using-the-dataset-validator/).

Use a back-end image such as `cbioportal/cbioportal:4.1.13` and mount the dataset into the container for running validation in offline mode, e.g. with the command: 
`docker run -e S=/cbioportal/nfosi_2022 -v $(pwd)/nfosi_2022:/cbioportal/nfosi_2022 -w /cbioportal/core/src/main/scripts/importer --entrypoint /bin/bash cbioportal/cbioportal:4.1.13 -c './validateData.py -s $S -p ../../../test/scripts/test_data/api_json_system_tests/ -v'`

Assuming your present working directory is `~/datahub/public` and a study folder called `nfosi_2022` has been placed into it, mount the dataset into the container and specify validation like so:
`docker run --rm -v $(pwd):/datahub cbioportal/cbioportal:4.1.13 validateStudies.py -d /datahub -l nfosi_2022 -u http://cbioportal.org -html /datahub/nfosi_2022/html_report`

 