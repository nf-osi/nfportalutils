---
title: "Annotating nextflow processed data"
output: rmarkdown::html_vignette
date: 2022-10-17
vignette: >
  %\VignetteIndexEntry{annotating-nextflow-processed-data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Intro

### Purpose

This vignette documents in-practice usage of the annotation utils for nf-processed data files.

The outputs are:  
1. A metadata manifest for a processed dataset that can be further validated with schematic before submission.
2. Provenance meta.

Typically, these are inspected/validated before submitting to Synapse as a final followup step.

Examples can be run with READ access only to processed outputs,
but requires you to have DOWNLOAD access or a local copy of the input samplesheet. 
To actually apply any annotations of course requires EDIT access.

### General idea 

<img src="https://raw.githubusercontent.com/nf-core/rnaseq/3.14.0//docs/images/nf-core-rnaseq_metro_map_grey.png" alt="nf-core-rnaseq_metro_map" width="800"/>

A nextflow workflow generates different types of outputs along the steps in the workflow (see figure above).
At some of these steps/stops, we have products that can be collected and packaged into "level 2, 3, or 4" datasets.
For example, the `.bam/bai` outputs from SAMtools represent a "level 2" semi-processed dataset with a dataType of `AlignedReads`.

Ideally, we would simply like to point to the main folder containing all processed output files and 
get back a list of manifests that represent all useful dataset products from the workflow. 
(What is a "useful", selectable data product is encoded in this annotation workflow.)

These manifests can then be used to annotate the files as well as for creation of [Synapse Datasets](https://help.synapse.org/docs/Datasets.2611281979.html). 


## Set up

First load the `nfportalutils` package and log in. 
The recommended default usage of `syn_login` is to use it without directly passing in credentials. 
Instead, have available the `SYNAPSE_AUTH_TOKEN` environment variable with your token stored therein.
```{r setup, eval=FALSE}
library(nfportalutils)
library(data.table)
syn_login()
```

### Steps

The general annotation workflow steps are:  
1. Parse the input samplesheet.  
2. Get basic context of processed outputs from the workflow run.  
Because none of the indexed-back output files have annotations,
we have to first construct initial info **sample**, **caller**, etc. out of the good ol' folder hierarchy and file names.  
3. Now with some sample and workflow context at least, link input-output data appropriately, check sample correspondence, 
and get into format expected for downstream.  
4. Transfer other meta from input to output processed files (most important are `individualID`, basic individual attributes, `assay`).  
5. Set annotations for processed data type based on workflow default rules.

Given the above steps, some potential issues should be noted:
- Processed data files will also be missing or incorrect for anything annotations in that state for input files 
- If sample ids and other information are updated on the original raw input files, data must be reannotated.
- Anything that deviates from a relatively standard workflow run, leading to changes in locations or naming of outputs,
might yield poor results for the annotation functionality here or require more manual composition of steps.

## nf-rnaseq 

Use `?map_sample_output_rnaseq` to see which outputs are handled in the parameter `output`. 
**But note that depending on how the workflow was run and data indexed back into Synapse, actual output availability may differ.**

In some projects, bam/bai files may not even be indexed back into Synapse. 
As an illustrative example, the workflow outputs here does not include featureCounts:

```{r rnaseq-1, eval=FALSE}

syn_out <- "syn57382909"
fileview <- "syn11601495"

o <- map_sample_output_rnaseq(syn_out, fileview) # check outputs only
names(o)

```

To continue, the example uses this output directory that does have all present from a standard nf-rnaseq workflow.
(Review the source code for `processed_meta` to see the steps encapsulated.)

```{r rnaseq-full, eval=FALSE}

samplesheet <- "syn51408030"
syn_out <- "syn51476810"
fileview <- "syn11601481"
wf_link <- "https://nf-co.re/rnaseq/3.11.2/output#star-and-salmon"

input <- map_sample_input_ss(samplesheet)
output <- map_sample_output_rnaseq(syn_out, fileview)
meta <- processed_meta(input, output, workflow_link = wf_link)

```


Inspect some manifests:
```{r, eval=FALSE}
 head(meta$manifests$SAMtools)
```

```{r, eval=FALSE}
head(meta$manifests$`STAR and Salmon`
```

### Add provenance

Use `sample_io` to add provenance meta with `add_activity_batch`. 

"Workflow" provides the general name to the activity, 
while "workflow link" provides a more persistent reference to some version/part of the workflow, 
which others can follow the link to get details. 

```{r rnaseq-add-provenance, eval=FALSE}

sample_io <- meta$sample_io
prov <- add_activity_batch(sample_io$output_id, 
                           sample_io$workflow, 
                           wf_link,
                           sample_io$input_id)
```

### Submit manifest

```{r rnaseq-meta-submit, eval=FALSE}
annotate_with_manifest(manifest_1)
```

### Create dataset

To create a [Synapse Dataset](https://help.synapse.org/docs/Datasets.2611281979.html):

```{r rnaseq-dataset, eval=FALSE}

items <- manifest_1$entityId
project <- "your-dev-project-synid"
dataset_1 <- new_dataset(name = "STAR Salmon Gene Expression Quantification from RNA-seq",
                         parent = project,
                         items = items,
                         dry_run = FALSE)
```


## nf-sarek

The only difference is usage of `map_sample_output_sarek` at Step 2.

```{r sarek-dataset, eval=FALSE}

samplesheet <- "syn38793905" # samplesheet can be stored on Synapse or locally
syn_out <- "syn27650634"
fileview <- "syn13363852"

i <- map_sample_input_ss(samplesheet) #1
o <- map_sample_output_sarek(syn_out, fileview) #2
sarek_meta <- processed_meta(i, o, workflow_link = "test")

# View first manifest
sarek_meta$manifests$Strelka2

```


### Add provenance

Use the manifest to add provenance. 

```{r sarek-add-provenance, eval=FALSE}

wf_link <- c(FreeBayes = "https://nf-co.re/sarek/3.2.3/output#freebayes",
             Mutect2 = "https://nf-co.re/sarek/3.2.3/output#gatk-mutect2",
             Strelka2 = "https://nf-co.re/sarek/3.2.3/output#strelka2")

add_activity_batch(sample_io$output_id, 
                   sample_io$workflow, 
                   wf_link[sample_io$workflow], 
                   sample_io$input_id)
   
```

After provenance, the rest of the workflow for manifest submission or creating datasets is like the nf-rnaseq example.

